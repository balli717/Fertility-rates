{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96d63b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping year 2022\n",
      "total pages 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Balli\\AppData\\Local\\Temp/ipykernel_20240/3165232653.py:133: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  l =driver.find_element_by_xpath(\"//button[text()='Next']\")  # using selenium navigation to next page\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of columns 6\n",
      "scraping year 2021\n",
      "total pages 34\n",
      "total number of columns 6\n",
      "scraping year 2020\n",
      "total pages 34\n",
      "total number of columns 6\n",
      "scraping year 2019\n",
      "total pages 34\n",
      "total number of columns 3\n",
      "scraping year 2018\n",
      "total pages 34\n",
      "total number of columns 3\n",
      "scraping year 2017\n",
      "total pages 33\n",
      "total number of columns 3\n",
      "scraping year 2016\n",
      "total pages 35\n",
      "total number of columns 3\n",
      "scraping year 2015\n",
      "total pages 35\n",
      "total number of columns 2\n",
      "scraping year 2014\n",
      "total pages 36\n",
      "total number of columns 2\n"
     ]
    }
   ],
   "source": [
    "# importing required pacakages\n",
    "# need beautifulSoup and Selenium; and excel packages\n",
    "\n",
    "import csv\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "driver = webdriver.Chrome() # works in chrome browser\n",
    "\n",
    "# warning all cockies will be deleted NECESSARY SINCE THE WEBISTE BLOCKS FURTHER USAGE ASKING FOR SUBMISSION\n",
    "\n",
    "driver.delete_all_cookies() \n",
    "\n",
    "\n",
    "\n",
    "for year in reversed(range(2014,2023)):    # Looped to scrape all the years\n",
    "    \n",
    "    #webiste changes year once data of single year is scraped\n",
    "    \n",
    "    url=(\"https://fortune.com/worlds-most-admired-companies/\"+str(year)+\"/search/?ordering=asc\")  \n",
    "    driver.get(url)\n",
    "    print(\"scraping year\",year)\n",
    "    \n",
    "    #Gving 2 sec to allow data to be load, this time has to increased if net speeds are low\n",
    "    \n",
    "    time.sleep(2)\n",
    "   \n",
    " \n",
    "\n",
    "    soup=BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # reading number of pages to know the range in which loop has to be run\n",
    "    \n",
    "    no_pages=soup.find_all('span',{\"class\": \"-totalPages\"})\n",
    "    \n",
    "    b=int(no_pages[0].text)\n",
    "    print(\"total pages\",b)\n",
    "    try:\n",
    "        \n",
    "        n_pg=b+1\n",
    "    except:\n",
    "        \n",
    "        n_pg=b\n",
    "    \n",
    "    #creating empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    #A list created to store all the values in tables on website  in sequence\n",
    "    pg_li=[]\n",
    "    \n",
    "\n",
    "    # loop to scrape for one year \n",
    "    \n",
    "    for page in range(1,n_pg):\n",
    "        \n",
    "        soup=BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # knowing columns so that we can create the table accordingly\n",
    "        \n",
    "        hed_cols=soup.find_all('div',{\"class\": \"searchResults__columnTitle--1Brf4\"})\n",
    "        col_list=[hed_cols[x].text for x in range(0,len(hed_cols))]\n",
    "        \n",
    "        # header names to give to the data frame\n",
    "        \n",
    "        hd=[hed_cols[x].text for x in range(0,len(hed_cols))]\n",
    "        \n",
    "        # tables row extraction\n",
    "        \n",
    "        tab_rows=soup.find_all('div',{\"class\": \"searchResults__cellContent--3WEWj\"})\n",
    "        li=[tab_rows[x].text for x in range(0,len(tab_rows))]\n",
    "        for m in li:\n",
    "            pg_li.append(m)\n",
    "        \n",
    "        #for one page\n",
    "        \n",
    "        if page==(n_pg-1):\n",
    "            cc=int(len(hed_cols))\n",
    "            print(\"total number of columns\",cc)\n",
    "            for x in range(0,cc):\n",
    "                col_list[x]=[]\n",
    "                n=x\n",
    "                z=int(len(pg_li)/cc)\n",
    "                \n",
    "                for a in range(0,z):\n",
    "                    r=pg_li[n]\n",
    "                    \n",
    "                    col_list[x].append(r)\n",
    "                    n=n+cc           # this helps to copy the element in next row in same column\n",
    "                df[x] = col_list[x]  #values of each row gets appended to specific column  df\n",
    "            \n",
    "            \n",
    "            df.columns = hd          # setting the column names to the data frame\n",
    "            \n",
    "            \n",
    "       \n",
    "        # Writing to different dataframes to be able to retrieved latter \n",
    "                \n",
    "        if int(year)==2014:\n",
    "            df1=df\n",
    "            \n",
    "        if int(year)==2015:\n",
    "            df2=df\n",
    "        if int(year)==2016:\n",
    "            df3=df\n",
    "        if int(year)==2017:\n",
    "            df4=df\n",
    "        if int(year)==2018:\n",
    "            df5=df\n",
    "        if int(year)==2019:\n",
    "            df6=df\n",
    "        if int(year)==2020:\n",
    "            df7=df\n",
    "        if int(year)==2021:\n",
    "            df8=df\n",
    "        if int(year)==2022:\n",
    "            df9=df\n",
    "        \n",
    "        # deleting cockies before going to another page\n",
    "\n",
    "        \n",
    "        driver.delete_all_cookies()\n",
    "        try:\n",
    "                 \n",
    "            l =driver.find_element_by_xpath(\"//button[text()='Next']\")  # using selenium navigation to next page\n",
    "            l.click()\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            \n",
    "            break\n",
    "            \n",
    "        # writing to different shhets in excel\n",
    "        \n",
    "writer2 = pd.ExcelWriter('Fortune_Magazine_3.xlsx')\n",
    "        \n",
    "df9.to_excel(writer2, sheet_name = '2022', index = False)\n",
    "df8.to_excel(writer2, sheet_name = '2021', index = False)\n",
    "df7.to_excel(writer2, sheet_name = '2020', index = False)\n",
    "df6.to_excel(writer2, sheet_name = '2019', index = False)\n",
    "df5.to_excel(writer2, sheet_name = '2018', index = False)\n",
    "df4.to_excel(writer2, sheet_name = '2017', index = False)\n",
    "df3.to_excel(writer2, sheet_name = '2016', index = False)\n",
    "df2.to_excel(writer2, sheet_name = '2015', index = False)\n",
    "\n",
    "#2014 data was not according to ranking, so had to sort data, for which needed to remove ',' to convert values into integers\n",
    "\n",
    "df['Rank']=df['Rank'].str.replace(',', '') \n",
    "df['Rank']=df['Rank'].apply(int)\n",
    "df1=df1.sort_values(by=['Rank'])\n",
    "df1.to_excel(writer2, sheet_name = '2014', index = False)\n",
    "\n",
    "writer2.save()  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a26f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf02ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e1bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
